{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0de74b11",
      "metadata": {
        "id": "0de74b11"
      },
      "source": [
        "# Segmentazione di edifici da immagini satellitari e classificazione del contesto urbano: notebook per training del modello di riconoscimento\n",
        "\n",
        "*Progetto di Visione Artificiale e Riconoscimento 2024/2025*\n",
        "\n",
        "- **Nome:** Pablo Sebastian\n",
        "- **Cognome:** Vargas Grateron\n",
        "- **Email:** pablo.vargasgrateron@studio.unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b528ea2d",
      "metadata": {
        "id": "b528ea2d"
      },
      "source": [
        "Questo progetto si concentra sulla segmentazione di edifici da immagini satellitari e sulla classificazione del contesto urbano. Utilizza tecniche di deep learning per analizzare immagini aeree e identificare edifici e altre strutture urbane."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ebd8bb",
      "metadata": {
        "id": "14ebd8bb"
      },
      "source": [
        "Il dataset utilizzato è il dataset [Inria Aerial Image Labeling](https://project.inria.fr/aerialimagelabeling/), che contiene immagini aeree ad alta risoluzione e le relative maschere di segmentazione degli edifici.\n",
        "\n",
        "> Assicurati di scaricare il dataset prima di eseguire il notebook e di avere al meno 50 GB di spazio libero su disco."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc781cfe",
      "metadata": {
        "id": "fc781cfe"
      },
      "source": [
        "## Librerie e percorsi dei dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54d36f17",
      "metadata": {
        "id": "54d36f17"
      },
      "source": [
        "Il codice contenuto nelle seguenti celle importa le librerie necessarie e definisce i percorsi per i dataset utilizzati nel progetto.\n",
        "\n",
        "> Assicurati di avere installato le librerie richieste contenute nel file `requirements.txt` prima di eseguire il notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad222698",
      "metadata": {
        "id": "ad222698"
      },
      "outputs": [],
      "source": [
        "import os, time, random\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "06b18ee7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06b18ee7",
        "outputId": "f3904e78-534b-4fa1-fbb0-3a6c67720618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF version: 2.19.0\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e566344c",
      "metadata": {
        "id": "e566344c"
      },
      "source": [
        "Per la prossima cella, assicurati di avere i seguenti percorsi impostati correttamente:\n",
        "- `PATH_DATASET_DIR`: percorso alla cartella principale dove sono memorizzati i dataset.\n",
        "- `PATH_DATASET`: percorso alla cartella contenente i dataset originali.\n",
        "- `PATH_PROCESSED_DATASET`: percorso alla cartella dove saranno memorizzati i dataset elaborati.\n",
        "- `PATH_MODEL`: percorso alla cartella dove sarà memorizzato il modello addestrato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "83ab6bc0",
      "metadata": {
        "id": "83ab6bc0"
      },
      "outputs": [],
      "source": [
        "PATH_DATASET_DIR = Path(\"../../dataset\")\n",
        "PATH_DATASET = PATH_DATASET_DIR / \"original\"\n",
        "PATH_PROCESSED_DATASET = PATH_DATASET_DIR / \"processed\"\n",
        "\n",
        "PATH_TRAIN_DATASET = PATH_DATASET / \"train\"\n",
        "PATH_TEST_DATASET = PATH_DATASET / \"test\"\n",
        "\n",
        "PATH_TRAIN_DATASET_PROCESSED = PATH_PROCESSED_DATASET / \"train\"\n",
        "PATH_TEST_DATASET_PROCESSED = PATH_PROCESSED_DATASET / \"test\"\n",
        "\n",
        "PATH_MODEL = Path(\"model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9vcEpgeAUcb5",
      "metadata": {
        "id": "9vcEpgeAUcb5"
      },
      "source": [
        "## Setup: caricamento del modello e processing delle immagini"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "019cfd72",
      "metadata": {},
      "source": [
        "Per utilizzare il modello addestrato, è necessario caricarlo e preparare le immagini per la classificazione. Nella seguente cella, eseguiamo queste operazioni.\n",
        "\n",
        "> Per procedere, assicurati di avere il modello addestrato nel primo notebook `1_model_training.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ffdce31",
      "metadata": {},
      "outputs": [],
      "source": [
        "JACCARD_INDEX_SMOOTH = 1e-12\n",
        "\n",
        "def jaccard_index(y_true, y_pred):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
        "    jac = (intersection + JACCARD_INDEX_SMOOTH) / (sum_ - intersection + JACCARD_INDEX_SMOOTH)\n",
        "    return K.mean(jac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "pz48qkmwUCFw",
      "metadata": {
        "id": "pz48qkmwUCFw"
      },
      "outputs": [],
      "source": [
        "dependencies = {'jaccard_index': jaccard_index}\n",
        "loaded_model=keras.models.load_model(PATH_MODEL / \"UnetWSatellite.keras\", custom_objects=dependencies)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "var_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
